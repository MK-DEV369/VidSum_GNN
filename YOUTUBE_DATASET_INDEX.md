# YouTube Dataset Builder - Complete Documentation Index

## ğŸ“ Quick Navigation

### ğŸš€ **Getting Started (Start Here)**
1. [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) - Overview of what was built
2. [EXECUTION_GUIDE.md](EXECUTION_GUIDE.md) - Step-by-step execution instructions
3. [YOUTUBE_DATASET_README.md](YOUTUBE_DATASET_README.md) - Detailed usage guide

### ğŸ”§ **Core Components**

#### Main Pipeline
- **youtube_dataset.py** - Complete video processing pipeline
  - Downloads management and configuration
  - Audio extraction (FFmpeg)
  - Shot detection (PySceneDetect)
  - Feature extraction (OpenCV, librosa)
  - Importance scoring (domain-weighted)
  - JSON dataset generation

#### Testing & Validation
- **test_youtube_dataset.py** - Comprehensive test suite (8/8 passing)
  - Data structure validation
  - Feature normalization
  - Importance scoring
  - Temporal smoothing
  - Rank assignment
  - Dataset validation
  - Directory structure
  - Playlist configuration

#### Download Tools
- **download_playlists.py** - Interactive playlist downloader
  - Uses yt-dlp for reliable downloads
  - Supports 1-20 videos per playlist
  - Progress tracking
  - Error handling

### ğŸ“Š **The 5 YouTube Playlists**

| # | Playlist | Domain | Focus | Importance Weights |
|---|----------|--------|-------|-------------------|
| 1 | **TED-Talks** | Lecture | Educational talks | Speech: 0.5, Scene: 0.3 |
| 2 | **Kurzgesagt** | Documentary | Science education | Motion: 0.3, Speech: 0.3 |
| 3 | **CNN-Breaking-News** | Documentary | News coverage | Motion: 0.3, Speech: 0.3 |
| 4 | **ESPN-Highlights** | Sports | Sports highlights | Motion: 0.5, Scene: 0.3 |
| 5 | **BBC-Learning** | Documentary | BBC educational | Motion: 0.3, Speech: 0.3 |

**Automatic domain-based importance weighting ensures each video type is processed correctly**

---

## ğŸ“ Directory Structure

```
ANN_Project/
â”œâ”€â”€ youtube_dataset.py              â† Main pipeline (ready to use)
â”œâ”€â”€ test_youtube_dataset.py         â† Test suite (all passing)
â”œâ”€â”€ download_playlists.py           â† Download script (ready)
â”œâ”€â”€ run_pipeline.bat                â† Complete automation (Windows)
â”‚
â”œâ”€â”€ Documentation/
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md   â† Project overview
â”‚   â”œâ”€â”€ EXECUTION_GUIDE.md          â† Step-by-step guide
â”‚   â”œâ”€â”€ YOUTUBE_DATASET_README.md   â† Detailed documentation
â”‚   â””â”€â”€ YOUTUBE_DATASET_INDEX.md    â† This file
â”‚
â”œâ”€â”€ Setup Scripts/
â”‚   â”œâ”€â”€ setup_youtube_dataset.bat   â† Windows setup
â”‚   â””â”€â”€ setup_youtube_dataset.sh    â† Linux/Mac setup
â”‚
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train.ipynb                 â† VidSumGNN model
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ videos/                 â† Downloaded MP4 videos
â”‚       â”‚   â”œâ”€â”€ TED-Talks/
â”‚       â”‚   â”œâ”€â”€ Kurzgesagt/
â”‚       â”‚   â”œâ”€â”€ CNN-Breaking-News/
â”‚       â”‚   â”œâ”€â”€ ESPN-Highlights/
â”‚       â”‚   â””â”€â”€ BBC-Learning/
â”‚       â”œâ”€â”€ complete_dataset.json   â† Main dataset (generated)
â”‚       â”œâ”€â”€ metadata/               â† Video metadata (generated)
â”‚       â”œâ”€â”€ features/               â† Per-video features (generated)
â”‚       â”œâ”€â”€ splits/                 â† Train/val/test split (generated)
â”‚       â””â”€â”€ processed/              â† PyTorch graphs (for model)
â”‚
â””â”€â”€ frontend/                        â† Web interface (separate)
```

---

## ğŸ¯ Workflow Overview

### Phase 1: Download (15-60 minutes)
```bash
python download_playlists.py
# Prompts for video count (1-20 per playlist)
# Downloads best MP4 quality from 5 playlists
# Output: MP4 files in model/data/videos/{playlist}/
```

### Phase 2: Process (10-30 minutes)
```bash
python youtube_dataset.py
# Extracts audio, detects shots, computes features
# Generates importance scores
# Output: JSON datasets in model/data/
```

### Phase 3: Integrate (in train.ipynb)
```python
import json
with open('model/data/complete_dataset.json') as f:
    dataset = json.load(f)
# Use dataset for training VidSumGNN
```

---

## ğŸ“Š Data Pipeline Details

### Input
- YouTube videos (MP4 format, any duration/resolution)

### Processing Steps
1. **Audio Extraction** (FFmpeg)
   - Extracts audio track
   - Converts to 16kHz mono WAV
   - Stored temporarily

2. **Shot Detection** (PySceneDetect)
   - Detects scene boundaries
   - Content-based threshold (default: 27.0)
   - Produces shot start/end timestamps

3. **Motion Feature** (OpenCV)
   - Computes optical flow
   - Averages magnitude over shot
   - Normalized to [0,1]

4. **Speech Feature** (librosa)
   - Extracts RMS energy
   - Indicates voice activity
   - Normalized to [0,1]

5. **Audio Energy** (numpy)
   - Mean absolute amplitude
   - Overall audio intensity
   - Normalized to [0,1]

6. **Scene Change** (binary)
   - 1.0 at shot boundaries
   - 0.0 within shots
   - Already in [0,1]

7. **Object Count** (placeholder)
   - Can be enhanced with object detection
   - Currently: 1.0 for all shots

8. **Importance Score**
   - Weighted average of features
   - Weights depend on domain:
     - Lecture: emphasize speech
     - Sports: emphasize motion
     - Documentary: balanced
     - Interview: speech with motion
     - Default: equal weights

9. **Temporal Smoothing**
   - Gaussian filter (Ïƒ=2.0)
   - Ensures temporal coherence
   - Prevents sharp importance jumps

10. **Rank Assignment**
    - Sorts shots by importance
    - Rank 1 = most important
    - Rank N = least important

### Output
- **complete_dataset.json** - Full dataset with all videos and shots
- **dataset_metadata.json** - Video-level statistics
- **{video_id}_features.json** - Per-video shot features
- **train_val_test_split.json** - 60/20/20 split by video_id

---

## ğŸ’¾ Data Format Reference

### Video Object
```json
{
  "video_id": "dQw4w9WgXcQ",
  "duration": 213.5,
  "domain": "lecture",
  "shots": [...]
}
```

### Shot Object
```json
{
  "start": 0.0,
  "end": 5.2,
  "importance": 0.85,
  "rank": 1,
  "features": {
    "motion": 0.3,
    "speech": 0.9,
    "scene_change": 0.0,
    "audio_energy": 0.8,
    "object_count": 1.0
  }
}
```

### Expected Stats (15-25 videos)
- Total videos: 15-25
- Total shots: 500-1500
- Duration: 2-6 hours
- Avg shots/video: 50-80
- Importance: [0.01, 0.99], mean â‰ˆ 0.45

---

## âœ… Test Coverage

| Test | Status | Coverage |
|------|--------|----------|
| Data structures | âœ… PASS | ShotFeatures, Shot, VideoDataset |
| Feature normalization | âœ… PASS | Min-max scaling to [0,1] |
| Importance scoring | âœ… PASS | 5 domain types verified |
| Temporal smoothing | âœ… PASS | Gaussian filter variance reduction |
| Rank assignment | âœ… PASS | Correct importance-based ordering |
| Dataset validation | âœ… PASS | Statistics computation |
| Directory structure | âœ… PASS | File organization |
| Playlist config | âœ… PASS | 5 playlists with domains |

**Result: 8/8 tests passing âœ…**

---

## ğŸš€ Quick Commands

```bash
# Setup (first time only)
pip install librosa opencv-python scenedetect scipy numpy yt-dlp

# Test pipeline
python test_youtube_dataset.py

# Download videos
python download_playlists.py

# Process videos
python youtube_dataset.py

# Automated execution (Windows)
run_pipeline.bat

# Check output
dir model\data\
```

---

## ğŸ“ˆ Expected Performance

### Download Performance
- Bandwidth: Depends on internet speed
- Videos per playlist: 1-20 (configurable)
- Typical: 500MB-1GB per 10 videos

### Processing Performance
- Audio extraction: 1-2 min per hour of video
- Shot detection: 0.5-1 min per hour
- Feature extraction: 2-5 min per hour
- Total: ~4-8 min per hour of video

### Storage Requirements
```
Videos: 2-4 GB (for 15-25 videos)
JSON output: 300-500 KB
Total: ~2-4 GB
```

---

## ğŸ”— Integration Points

### With train.ipynb
```python
# Load dataset
import json
with open('model/data/complete_dataset.json') as f:
    dataset = json.load(f)

# Load splits
with open('model/data/splits/train_val_test_split.json') as f:
    splits = json.load(f)

# Filter by split
train_videos = [v for v in dataset if v['video_id'] in splits['train']]
```

### Graph Conversion for GNN
```python
# Build temporal graphs
edges = []
features = []
labels = []

for video in dataset:
    shots = video['shots']
    for i, shot in enumerate(shots):
        # Node features
        features.append([shot['features']['motion'],
                        shot['features']['speech'],
                        shot['features']['scene_change'],
                        shot['features']['audio_energy'],
                        shot['features']['object_count']])
        # Importance labels
        labels.append(shot['importance'])
        
    # Temporal edges
    for i in range(len(shots)-1):
        edges.append([i, i+1])
```

---

## ğŸ› Common Issues & Solutions

| Issue | Cause | Solution |
|-------|-------|----------|
| `yt-dlp not found` | Not installed | `pip install yt-dlp` |
| `No module named 'librosa'` | Dependencies missing | Run setup script |
| `ffmpeg not found` | Not in PATH | Add to PATH or reinstall |
| Out of memory | Too many videos | Reduce playlist size |
| Very slow | Low bandwidth | Check internet speed |

---

## ğŸ“š Related Documentation

- [IMPLEMENTATION_SUMMARY.md](IMPLEMENTATION_SUMMARY.md) - Complete project overview
- [EXECUTION_GUIDE.md](EXECUTION_GUIDE.md) - Detailed execution steps
- [YOUTUBE_DATASET_README.md](YOUTUBE_DATASET_README.md) - Configuration & advanced usage
- train.ipynb - VidSumGNN model and training code

---

## ğŸ“ For Model Training

Once dataset is generated and saved:

1. **Load** the complete_dataset.json
2. **Extract** features and labels per shot
3. **Build** temporal graphs with shot-to-shot edges
4. **Create** train/val/test dataloaders using provided splits
5. **Train** VidSumGNN with importance scores as labels
6. **Evaluate** using F-score and Spearman correlation

---

## âœ¨ Key Features

âœ… Automated video download from 5 major playlists  
âœ… Domain-specific importance weighting  
âœ… Comprehensive feature extraction (visual + audio)  
âœ… Temporal coherence through smoothing  
âœ… Organized JSON output format  
âœ… Train/val/test splits included  
âœ… Complete test suite (8/8 passing)  
âœ… Integration-ready for train.ipynb  

---

## ğŸ¯ Next Steps

1. **Read** EXECUTION_GUIDE.md for detailed instructions
2. **Run** `python test_youtube_dataset.py` to verify setup
3. **Execute** `python download_playlists.py` to download videos
4. **Run** `python youtube_dataset.py` to generate datasets
5. **Integrate** with train.ipynb for model training

**Estimated total time: 1-3 hours for complete dataset**

---

**Status: âœ… READY FOR PRODUCTION USE**

All components tested, documented, and ready to generate YouTube-based video summarization datasets.
